{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc99060a",
   "metadata": {},
   "source": [
    "# LLM Testing\n",
    "\n",
    "Here we test the LLM and check that it works as wanted with the Ollama setup.\n",
    "\n",
    "Before running this file it is needed to install Ollama and the LLaMA 3.1 model as explained in the `setup_instruction.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e99b53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4931368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_call(prompt):\n",
    "    \"\"\"\n",
    "    Function to test a simple call to the LLM model using Ollama.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the LLM.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the LLM.\n",
    "    \"\"\"\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.1:8b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        options={\n",
    "            \"temperature\": 0.2\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d673fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What color is a strawberry?\n",
      "LLM Response: A strawberry is typically red in color, although some varieties may have a slightly yellow or white tint to them. The exact shade of red can vary depending on the ripeness and type of strawberry!\n"
     ]
    }
   ],
   "source": [
    "# simple test to check if ollama and LLM calls work\n",
    "prompt = \"What color is a strawberry?\"\n",
    "response = simple_call(prompt)\n",
    "print(\"Prompt:\", prompt)\n",
    "print(\"LLM Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedeb164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon-energy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
